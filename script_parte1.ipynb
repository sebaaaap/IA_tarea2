{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 - CARGA Y PREPROCESAMIENTO<br>\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle, os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_NAME = \"dataset_t2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_NAME):\n",
    "    print(\"No se encontró el dataset_t2.csv\")\n",
    "    print(\"Colócalo en la misma carpeta y vuelve a ejecutar el script.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con 15000 filas y 9 columnas.\n",
      "   User-ID        ISBN  Book-Rating  Avg_User_Rating  Num_Ratings_User  \\\n",
      "0   276725  034545104X            0             4.37               412   \n",
      "1   276726  0155061224            5             9.56               278   \n",
      "2   276727  0446520802            0             7.59               493   \n",
      "3   276729  052165615X            3             6.39                16   \n",
      "4   276729  0521795028            6             2.40                13   \n",
      "\n",
      "   Book_Popularity  Book_Pages  Book_Year Rating_Category  \n",
      "0             55.7         308       1994            Bajo  \n",
      "1             36.7        1177       2000           Medio  \n",
      "2             19.6         413       1983            Bajo  \n",
      "3             24.9         418       1997            Bajo  \n",
      "4             22.2        1007       1986           Medio  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_NAME)\n",
    "print(f\"Dataset cargado con {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 - VARIABLES X e Y<br>\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_col = \"Rating_Category\"\n",
    "X_cols = [c for c in df.columns if c != Y_col and df[c].dtype != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[X_cols]\n",
    "Y = df[Y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables usadas para clustering:\n",
      "['User-ID', 'Book-Rating', 'Avg_User_Rating', 'Num_Ratings_User', 'Book_Popularity', 'Book_Pages', 'Book_Year']\n",
      "Etiqueta Y: Rating_Category (clases: ['Bajo' 'Medio' 'Alto'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Variables usadas para clustering:\")\n",
    "print(X_cols)\n",
    "print(f\"Etiqueta Y: {Y_col} (clases: {df[Y_col].unique()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 - DIVISIÓN DE DATOS<br>\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 12000 filas, Test: 3000 filas\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f\"Train: {len(X_train)} filas, Test: {len(X_test)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 - NORMALIZACIÓN<br>\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"clustering_outputs\", exist_ok=True)\n",
    "pickle.dump(scaler, open(\"clustering_outputs/scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 - ENTRENAMIENTO Y EVALUACIÓN<br>\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuraciones kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(k=3, init=random) - Silhouette = 0.139\n",
      "KMeans(k=3, init=k-means++) - Silhouette = 0.112\n",
      "KMeans(k=4, init=random) - Silhouette = 0.145\n",
      "KMeans(k=4, init=k-means++) - Silhouette = 0.125\n",
      "KMeans(k=5, init=random) - Silhouette = 0.133\n",
      "KMeans(k=5, init=k-means++) - Silhouette = 0.132\n",
      "KMeans(k=6, init=random) - Silhouette = 0.134\n",
      "KMeans(k=6, init=k-means++) - Silhouette = 0.136\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 4, 5, 6]:\n",
    "    for init_method in [\"random\", \"k-means++\"]:\n",
    "        model = KMeans(n_clusters=k, init=init_method, random_state=42)\n",
    "        labels = model.fit_predict(X_train_scaled)\n",
    "        score = silhouette_score(X_train_scaled, labels)\n",
    "        models_info.append({\n",
    "            \"model\": model,\n",
    "            \"name\": f\"KMeans_k={k}_{init_method}\",\n",
    "            \"silhouette\": score\n",
    "        })\n",
    "        print(f\"KMeans(k={k}, init={init_method}) - Silhouette = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuraciones meanshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanShift(q=0.2) - Silhouette = 0.377\n",
      "MeanShift(q=0.3) - Silhouette = 0.377\n",
      "MeanShift(q=0.4) - Silhouette = 0.377\n",
      "MeanShift(q=0.5) - Silhouette = 0.377\n"
     ]
    }
   ],
   "source": [
    "for quantile in [0.2, 0.3, 0.4, 0.5]:\n",
    "    bandwidth = estimate_bandwidth(X_train_scaled, quantile=quantile)\n",
    "    model = MeanShift(bandwidth=bandwidth)\n",
    "    labels = model.fit_predict(X_train_scaled)\n",
    "    score = silhouette_score(X_train_scaled, labels)\n",
    "    models_info.append({\n",
    "        \"model\": model,\n",
    "        \"name\": f\"MeanShift_q={quantile:.1f}\",\n",
    "        \"silhouette\": score\n",
    "    })\n",
    "    print(f\"MeanShift(q={quantile:.1f}) - Silhouette = {score:.3f}\")\n",
    "    \n",
    "# Resumen general\n",
    "results_df = pd.DataFrame([\n",
    "    {\"Modelo\": m[\"name\"], \"Silhouette\": round(m[\"silhouette\"], 4)}\n",
    "    for m in models_info\n",
    "]).sort_values(\"Silhouette\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANKING MODELOS (Top 12)\n",
      "                  Modelo  Silhouette\n",
      "8        MeanShift_q=0.2      0.3774\n",
      "9        MeanShift_q=0.3      0.3774\n",
      "10       MeanShift_q=0.4      0.3774\n",
      "11       MeanShift_q=0.5      0.3774\n",
      "2      KMeans_k=4_random      0.1453\n",
      "0      KMeans_k=3_random      0.1390\n",
      "7   KMeans_k=6_k-means++      0.1359\n",
      "6      KMeans_k=6_random      0.1344\n",
      "4      KMeans_k=5_random      0.1332\n",
      "5   KMeans_k=5_k-means++      0.1317\n",
      "3   KMeans_k=4_k-means++      0.1254\n",
      "1   KMeans_k=3_k-means++      0.1115\n"
     ]
    }
   ],
   "source": [
    "print(\"RANKING MODELOS (Top 12)\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda resultados, ver en el editor de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"clustering_outputs/model_silhouette_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 - APLICAR LOS 3 MEJORES MODELOS AL TEST<br>\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 1: MeanShift_q=0.2 - Precisión mapeada = 0.618\n",
      "Modelo 2: MeanShift_q=0.3 - Precisión mapeada = 0.618\n",
      "Modelo 3: MeanShift_q=0.4 - Precisión mapeada = 0.618\n"
     ]
    }
   ],
   "source": [
    "top3 = results_df.head(3)\n",
    "for i, name in enumerate(top3[\"Modelo\"], 1):\n",
    "    model = [m for m in models_info if m[\"name\"] == name][0][\"model\"]\n",
    "    pickle.dump(model, open(f\"clustering_outputs/model_top{i}.pkl\", \"wb\"))\n",
    "\n",
    "    # predicción en test, si vemos la densidad predomina la clase 'baja'\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    df_result = pd.DataFrame({\n",
    "        \"Cluster\": preds,\n",
    "        \"Y_real\": Y_test.values\n",
    "    })\n",
    "\n",
    "    # mapeo cluster → clase dominante\n",
    "    mapping = df_result.groupby(\"Cluster\")[\"Y_real\"].agg(lambda x: x.mode()[0])\n",
    "    df_result[\"Y_pred\"] = df_result[\"Cluster\"].map(mapping)\n",
    "\n",
    "    # precisión simple\n",
    "    accuracy = (df_result[\"Y_real\"] == df_result[\"Y_pred\"]).mean()\n",
    "    print(f\"Modelo {i}: {name} - Precisión mapeada = {accuracy:.3f}\")\n",
    "\n",
    "    # guardar resultados\n",
    "    df_result.to_csv(f\"clustering_outputs/test_labels_model_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Revisa la carpeta clustering_outputs/\n"
     ]
    }
   ],
   "source": [
    "print(\"Proceso completado. Revisa la carpeta clustering_outputs/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
